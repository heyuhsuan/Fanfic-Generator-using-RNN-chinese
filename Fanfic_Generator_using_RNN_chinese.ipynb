{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "# Demo RNN -- AI二次創作\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoKPksUD96Mb",
        "outputId": "d069d5e2-b4c1-4b8d-a272-14915a455f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HvuKZLAmenzqAoyAcYVf0VFKmasl0tN5\n",
            "To: /content/Animal farm.txt\n",
            "100% 163k/163k [00:00<00:00, 77.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "!gdown --id 1HvuKZLAmenzqAoyAcYVf0VFKmasl0tN5 --output \"./Animal farm.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "c8fb25f0-9828-4ac7-9fe2-feb86fb8a1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Animal farm共有 55564 字詞\n",
            "包含了 2377 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一六年七月一日版》\n",
            "《好讀書櫃》典藏版\n",
            "作者介紹\n",
            "英國作家喬治•歐威爾原名艾瑞克•亞瑟•布萊爾（Eric Arthur Blair），除了小說，也寫紀實及評論性質的散文，一九四○年代末期因兩部諷諭傑作《動物農莊》（Animal Farm：A Fairy Story）與《一九八四》（Nineteen Eighty─Four）聲名大噪，躍身為二十世紀最重要也最具影響力的文豪之一。\n",
            "※※※\n",
            "〈反抗的名字如此誕生〉\n",
            "一九○三年，歐威爾生於印度的一座村莊蒙地哈里（Motihari），當時的印度為英國殖民地，歐威爾的父親任職於印度總督府鴉片局（Opium Department of the Indian Civil Service），家境稱不上富裕，一如當時許多中產階級英國家庭，身無恆產，生計及前景完全仰賴帝國政府。歐威爾日後自嘲為「中產階級下層分子」（lower─upper─middle class）。一九○七年，歐威爾隨母親回到英國，父親留在印度工作直至一九二一年退休為止。\n",
            "在一九四七年發表的〈我為何寫作〉（「Why I Write」）一文中，歐威爾自述早在五、六歲的年紀便有心成為作家\n"
          ]
        }
      ],
      "source": [
        "book = \"\"\n",
        "with open(\"./Animal farm.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"Animal farm共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "outputs": [],
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "aa6544f2-0317-4fa0-8fbd-555a995c125b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "去除次數小於8的文字剩餘 : 891\n"
          ]
        }
      ],
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "611afb1e-7fcf-48d4-8496-4cf29e551170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "原本Animal farm共有 55564 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘50958個字\n"
          ]
        }
      ],
      "source": [
        "print(f\"原本Animal farm共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "70cf86b0-e43b-46c4-bc57-119d1d3f9355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '○', '一', '六', '年', '七', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '版', '\\n', '作', '者', '\\n', '英', '國', '作', '家', '治', '•', '歐', '威', '爾', '原', '名', '克', '•', '•', '布', '爾']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{771, 654, 782, 655, 662, 540, 798, 293, 550, 681, 429, 818, 696, 569, 830, 831, 835, 579, 603, 477, 98, 99, 877, 365, 626, 499, 627, 628, 887}\n"
          ]
        }
      ],
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "outputs": [],
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "c99204cf-b528-43c5-888b-b5d13fcc109b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[877 626 603  98 887 499 818 540 569 887 696 654 627 877 626 798 365 681\n",
            " 627 654 877], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '○', '一', '六', '年', '七', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '版', '\\n']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[831 830 877 771 782 831 835 293 429 477 662 628 579 655  99 429 429 550\n",
            " 628 765 772], shape=(21,), dtype=int32)\n",
            "['作', '者', '\\n', '英', '國', '作', '家', '治', '•', '歐', '威', '爾', '原', '名', '克', '•', '•', '布', '爾', '（', 'r']\n"
          ]
        }
      ],
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "b4501360-8d38-4803-93f8-704fd5d552ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "79af0a71-c7b5-4943-bfc8-e2a2b83998f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : ['\\n', '《', '二', '○', '一', '六', '年', '七', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '版']\n",
            "Target: ['《', '二', '○', '一', '六', '年', '七', '月', '一', '日', '版', '》', '\\n', '《', '好', '讀', '書', '》', '版', '\\n']\n",
            "--------------------------------------------------\n",
            "Input : [877 626 603  98 887 499 818 540 569 887 696 654 627 877 626 798 365 681\n",
            " 627 654]\n",
            "Target: [626 603  98 887 499 818 540 569 887 696 654 627 877 626 798 365 681 627\n",
            " 654 877]\n"
          ]
        }
      ],
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "b8497cd1-5963-4eea-a548-59a998fb1c22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "e85971f7-e6b3-401b-f284-8dd22e831cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         456192    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 891)         1825659   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,135,547\n",
            "Trainable params: 128,135,547\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "7f8fe750-b841-45fb-cfca-c07346e4d1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 891)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ],
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "f06a9703-8651-4492-f8cb-208e66f99427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "存在且應該維下去的友。豬和人類之間沒有、\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "結像形形無吧吧收收剛剛（內內八八八著著失\n"
          ]
        }
      ],
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "e5e9062d-632d-418b-8751-efc05a8ec347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "37/37 [==============================] - 10s 158ms/step - loss: 6.3794\n",
            "Epoch 2/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 6.0010\n",
            "Epoch 3/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 5.8307\n",
            "Epoch 4/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 5.5117\n",
            "Epoch 5/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 5.2354\n",
            "Epoch 6/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 5.0077\n",
            "Epoch 7/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 4.7625\n",
            "Epoch 8/20\n",
            "37/37 [==============================] - 6s 157ms/step - loss: 4.5003\n",
            "Epoch 9/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 4.1977\n",
            "Epoch 10/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 3.8015\n",
            "Epoch 11/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 3.3165\n",
            "Epoch 12/20\n",
            "37/37 [==============================] - 6s 159ms/step - loss: 2.7133\n",
            "Epoch 13/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 2.0061\n",
            "Epoch 14/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 1.3261\n",
            "Epoch 15/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.8142\n",
            "Epoch 16/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.5396\n",
            "Epoch 17/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.4037\n",
            "Epoch 18/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.3287\n",
            "Epoch 19/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.2826\n",
            "Epoch 20/20\n",
            "37/37 [==============================] - 6s 158ms/step - loss: 0.2521\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xxbK80fXpOWD",
        "outputId": "89dec8ed-3d51-41ce-8baa-e6a1ffb36143"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wUdf7H8dcnnRQSIAHpEIqKiJQIKEXsXdSzIthQ7Ip63p3n9fK7ondWLKCcHiJgw7MrqFSPEqogCAHpCKEmEAgh+f7+2MWLmEAos7Pl/Xw89pHNzkzmnc3mncnM7HfMOYeIiESfOL8DiIiIN1TwIiJRSgUvIhKlVPAiIlFKBS8iEqVU8CIiUUoFLwKY2ctm9qcazrvCzM460q8j4jUVvIhIlFLBi4hEKRW8RIzgrpGHzGy+me00s5fMrIGZfWRmxWY23szqVJr/EjNbaGbbzGyCmR1faVonM5sdXG4MkLLfui4ys7nBZb80sw6HmflWMyswsy1m9q6ZNQo+bmb2uJltNLMiM/vKzNoHp11gZl8Hs601s58e1hMmMU8FL5HmJ8DZQFvgYuAj4JdADoHX870AZtYWGAUMDk77EHjPzJLMLAl4BxgB1AXeCH5dgst2AoYDtwH1gBeAd80s+VCCmtkZwF+Aq4CGwEpgdHDyOUDv4PeRGZxnc3DaS8BtzrkMoD3w+aGsV2QfFbxEmqedcxucc2uBycB059wc59xuYCzQKTjf1cAHzrlxzrky4DGgFnAq0B1IBJ5wzpU5594EZlZaxyDgBefcdOdcuXPuFaA0uNyhuA4Y7pyb7ZwrBR4GTjGzFkAZkAEcB5hzbpFzbn1wuTKgnZnVds5tdc7NPsT1igAqeIk8Gyrd31XF5+nB+40IbDED4JyrAFYDjYPT1rofjrS3stL95sCDwd0z28xsG9A0uNyh2D/DDgJb6Y2dc58DzwBDgI1mNtTMagdn/QlwAbDSzCaa2SmHuF4RQAUv0WsdgaIGAvu8CZT0WmA90Dj42D7NKt1fDfzZOZdV6ZbqnBt1hBnSCOzyWQvgnHvKOdcFaEdgV81DwcdnOuf6AvUJ7Ep6/RDXKwKo4CV6vQ5caGZnmlki8CCB3SxfAv8F9gL3mlmimV0OdK207DDgdjPrFjwYmmZmF5pZxiFmGAXcZGYdg/vv/4/ALqUVZnZy8OsnAjuB3UBF8BjBdWaWGdy1VARUHMHzIDFMBS9RyTn3DdAfeBrYROCA7MXOuT3OuT3A5cCNwBYC++vfrrRsPnArgV0oW4GC4LyHmmE88GvgLQL/NbQCrglOrk3gD8lWArtxNgOPBqcNAFaYWRFwO4F9+SKHzHTBDxGR6KQteBGRKKWCFxGJUip4EZEopYIXEYlSCX4HqCw7O9u1aNHC7xgiIhFj1qxZm5xzOVVNC6uCb9GiBfn5+X7HEBGJGGa2srpp2kUjIhKlVPAiIlFKBS8iEqVU8CIiUUoFLyISpVTwIiJRSgUvIhKloqLgn/psKQvWbvc7hohIWIn4gt9WsodRM1Zx+XNfMnL6SjT8sYhIQMQXfFZqEh/c24vuufV4ZOwC7h8zl52le/2OJSLiu4gveIC6aUm8fOPJPHB2W/4zbx19h0xl6YZiv2OJiPgqKgoeIC7OuPfMNrw6sBvbSvZwyTNTeWfOWr9jiYj4JmoKfp8erbP54N5enNg4k8Fj5vLLsV+xu6zc71giIiEXdQUP0KB2Cq/d2o3bTsvltemruOL5L1m1ucTvWCIiIRWVBQ+QEB/Hw+cfz7Dr81i1uYQLn57MJwu/8zuWiEjIRG3B73N2uwZ8cG8vWtRL47YRs/jzB19TVl7hdywREc9FfcEDNK2bypt3nMKA7s0ZNvlbrh06je+27/Y7loiIpzwteDPLMrM3zWyxmS0ys1O8XN+BJCfE88dL2/PkNR35en0RFzw1mclLC/2KIyLiOa+34J8EPnbOHQecBCzyeH0H1bdjY969uyfZ6UlcP3wGT4xfQnmF3v0qItHHs4I3s0ygN/ASgHNuj3Num1frOxSt66fzzl09uKxjY54Yv5Qb/zWD1Vt0lo2IRBfzauwWM+sIDAW+JrD1Pgu4zzm3c7/5BgGDAJo1a9Zl5cpqrx971DnnGD1zNb99dyF79lbQpXkdLu7QkAs6NKR+RkrIcoiIHC4zm+Wcy6tymocFnwdMA3o456ab2ZNAkXPu19Utk5eX5/Lz8z3JcyCrt5Tw7rx1vDdvHYu/KybOoHtuPS4+qRHnnXAMddKSQp5JRKQm/Cr4Y4BpzrkWwc97Ab9wzl1Y3TJ+FXxlSzYU8/68dbw3fz3fbtpJQpzRs002F3doxNknNKB2SqKv+UREKvOl4IMrngzc4pz7xsx+B6Q55x6qbv5wKPh9nHMsXFfEe/PX8f689azdtoukhDhOPzaHi09qxBnH1Sc1KcHvmCIS4/ws+I7Ai0ASsBy4yTm3tbr5w6ngK3POMXvVNt6bt44Pv1rPxuJSaiXGc1a7BlzcoSGnHZtDckK83zFFJAb5VvCHKlwLvrLyCseMb7fw3vx1fPTVeraWlJGRksANp7Tg7jNak5KooheR0FHBe6SsvIKpBZt4Y9YaPpi/ntzsNP5y+Yl0y63ndzQRiREHKviYGKrAK4nxcfQ5tj5D+nVmxMCu7Cmv4Oqh0/jl2K8o2l3mdzwRiXEq+KOkV5scPr2/N7f0bMnoGas4+58T+VSjV4qIj1TwR1FqUgK/uqgdY+/sQZ3UJAaNmMVdI2ezsVgDm4lI6KngPXBS0yzeu6cnD517LOMWbeDsf07i9fzVhNPxDhGJfip4jyTGx3HX6a356L5eHNsgg5+9OZ/+L03XlaVEJGRU8B5rlZPO6EHd+dOl7Zm3ejvnPDGRYZOWs1cXHRERj6ngQyAuzujfvTnjHziNnq1z+POHi7j8uS/5el2R39FEJIqp4EPomMwUhl3fhSH9OrNu2y4ufmYKf/94MbvLyv2OJiJRSAUfYmbGhR0aMv6B07i8U2OenbCMC56czNSCTX5HE5Eoo4L3SVZqEo9eeRKvDuzG3grHdS9O5+aXZ7J0Q7Hf0UQkSqjgfdazTTaf3t+bh88/jpkrtnDuE5P45divKCwu9TuaiEQ4jUUTRrbs3MNTny3l1WkrSU6I444+rRjYM5daSRrATESqprFoIkTdtCR+d8kJfHp/b3q2yeaxT5dwxj8m8NasNVTowuAicohU8GEoNyedFwbkMWZQd3IyknnwjXlc/MwUvlymA7EiUnMq+DDWLbce79zZgyev6ci2kjL6DZvOLa/MpGDjDr+jiUgEUMGHubg4o2/Hxnz24Gn8/LzjmL48cCD21+8sYNMOHYgVkeqp4CNESmI8d/RpxYSH+nBdt2a8NmMVfR6dwLMTCvRGKRGpks6iiVDLCnfwlw8XM37RBhplpnDvmW24rHNjXRtWJMbokn1R7L/LNvOXjxYxf812cjKSualHC67r1pzMWol+RxOREFDBRznnHFMLNvPCpGVMXrqJtKR4runajJt7tqRxVi2/44mIh1TwMWThuu0Mm7Sc9+avx4CLT2rEoN65HN+wtt/RRMQDKvgYtHbbLoZP+ZZRM1ZRsqec3m1zuL13Lqe0qoeZ+R1PRI4SFXwM215SxqvTV/KvqSvYtKOU9o1rc1vvVpzf/hgS4nUSlUik863gzWwFUAyUA3urC7GPCt47u8vKeWfOWoZOXs7ywp00qVOLW3q25KqTm5KalOB3PBE5TH4XfJ5zrkbvsVfBe6+iwjF+0QaGTlpO/sqtZKUmcn335txwagvqpSf7HU9EDpEKXqo0a+UWXpi4nHGLNpCSEE//7s0Y1LsVORkqepFI4WfBfwtsBRzwgnNuaBXzDAIGATRr1qzLypUrPcsjVSvYuINnvyjgnblrSUqIo1/X5tx+Wi71a6f4HU1EDsLPgm/snFtrZvWBccA9zrlJ1c2vLXh/rdi0k2e+KGDsnLXExxn9ujbj9tNacUymil4kXIXFWTRm9jtgh3PusermUcGHh1WbSxjyRQFvzV5DnBlXn9yU2/u00pumRMKQLwVvZmlAnHOuOHh/HPAH59zH1S2jgg8vq7eU8OyEZbw5azUAV3Rpyp19WtG0bqrPyURkH78KPhcYG/w0AXjNOffnAy2jgg9Pa7ft4rkJBbw+cw0VzvGTzk246/TWNKunohfxW1jsoqkJFXx4W799F89PWMaomaspr3Bc1qkxd53empbZaX5HE4lZKng5qjYU7eaFicsZOX0lZeUVXNqxMXef0ZrcnHS/o4nEHBW8eGJj8W6GTVrOiGkrKSt3XNmlCfed1YaGmToYKxIqKnjxVGFxKUO+KGDk9JWYGTec0pw7+rSmblqS39FEop4KXkJi9ZYSnhi/lLFz1pCalMCtvXIZ2Ksl6cka60bEKyp4CamlG4p57NNv+GThBuqlJXHn6a25rlszUhJ1OUGRo00FL76Yu3obj36ymKkFm2mUmcLgs9pyeefGGqZY5Cg6UMHrN00807FpFiNv6c6rA7uRk5HMz96az7lPTOKjr9YTThsWItFKBS+e69kmm3fu6sHz/TtjZtwxcjZ9h0xlytIaDTIqIodJBS8hYWac174hnwzuzaNXdGDzjj30f2k6/YZNY86qrX7HE4lKKngJqfg448q8pnz+09P47cXt+Oa7Yi579kvuGjmb9dt3+R1PJKqo4MUXyQnx3NSjJRN/djqDz2rD+EUbOOsfE3lx8nLKyiv8jicSFVTw4qv05AQGn9WW8Q+cRrfcevzpg0Vc/PQUZq7Y4nc0kYingpew0LRuKi/dkMfQAV0o3r2XK5//Lw+9MY/NO0r9jiYSsVTwEjbMjHNOOIZxD/Tmjj6tGDtnLWf8YyKvTV9FRYVOqxQ5VCp4CTupSQn8/Lzj+Oi+XhzfMINfjv2Ky577kgVrt/sdTSSiqOAlbLVpkMGoW7vz+NUnsXZrCZc8M4Xf/mcB23eV+R1NJCKo4CWsmRmXdWrCZw/2YUD35oyYtpIz/zGRd+as1bthRQ5CBS8RIbNWIr/v257/3NWTxlkpDB4zl2uHTaNgY7Hf0UTClgpeIsqJTTJ5+84e/Pmy9ny9rojzn5zM3z5eTMmevX5HEwk7KniJOPFxxnXdmvP5T/vQt2NjnpuwjIufnkLBxh1+RxMJKyp4iVjZ6ck8duVJjLylG9tKyrh0yFTGfb3B71giYUMFLxGvR+ts3r2nJy2z07j13/k8Pm6JzpsXQQUvUaJxVi3euP0UftK5CU9+tpRBI/Ip2q3TKSW2eV7wZhZvZnPM7H2v1yWxLSUxnseu7MDvLzmBCd8UcukzU3WWjcS0UGzB3wcsCsF6RDAzbji1BSNv6UbR7jL6PjOVTxZ+53csEV94WvBm1gS4EHjRy/WI7K9bbj3eu6cnreunc9uIWfzj02+0X15ijtdb8E8APwOqHeDbzAaZWb6Z5RcWFnocR2JJw8xajLntFK7s0oSnPy9g4CszNcyBxBTPCt7MLgI2OudmHWg+59xQ51yecy4vJyfHqzgSo1IS4/n7FR3446Xtmbx0E32fmcKSDdovL7HByy34HsAlZrYCGA2cYWaverg+kSqZGQO6N2fUoO7sKC3n0iFT+eir9X7HEvGcZwXvnHvYOdfEOdcCuAb43DnX36v1iRzMyS3q8v49PTn2mAzuGDmbv3+8mHLtl5copvPgJaYck5nC6EHdubZrU56dsIybX57J9hLtl5foFJKCd85NcM5dFIp1iRxMckI8f7m8A/932Yl8uWwTlwyZwjffab+8RB9twUvM6tetGaMHncKuPeVc9cJ/mb9mm9+RRI4qFbzEtC7N6/DWHadSu1YC1w2bzuxVW/2OJHLUqOAl5jWtm8qYQadQLz2J61+awcwVW/yOJHJUqOBFgEZZgTdF1a+dzA3DZ/DfZZv9jiRyxFTwIkENaqcwZtApNKlTi5tensHkpXpntUQ2FbxIJTkZyYy6tTst6qUx8JV8vvhmo9+RRA6bCl5kP/XSAyXftkE6t/17lq4SJRFLBS9ShTppSYy8pTvHN6rNHa/O0tAGEpFU8CLVyKyVyIiBXTmpaRZ3j5rDe/PW+R1J5JCo4EUOoHZKIq/c3JUuzetw3+g5jJ2zxu9IIjVWo4I3s/vMrLYFvGRms83sHK/DiYSD9OQEXr7pZLrn1uOB1+fxev5qvyOJ1EhNt+Bvds4VAecAdYABwF89SyUSZlKTEhh+48n0bJ3Nz96cz2vTV/kdSeSgalrwFvx4ATDCObew0mMiMSElMZ5h1+dxxnH1+eXYr3jlyxV+RxI5oJoW/Cwz+5RAwX9iZhkc4DJ8ItEqJTGe5/t34Zx2Dfjtuwt5cfJyvyOJVKumBT8Q+AVwsnOuBEgEbvIslUgYS0qIY8h1nbnwxIb86YNFPDdhmd+RRKqUUMP5TgHmOud2mll/oDPwpHexRMJbYnwcT17TkYR4428fL8bhuLNPa79jifxATbfgnwNKzOwk4EFgGfBvz1KJRICE+Dj+eVVH+nZsxN8//kZvhpKwU9OC3+ucc0Bf4Bnn3BAgw7tYIpEhPs74+xUd6Nwsiwden8fCddv9jiTyvZoWfLGZPUzg9MgPzCyOwH54kZiXnBDP8wO6kJWayK2v5FNYXOp3JBGg5gV/NVBK4Hz474AmwKOepRKJMPUzUhh2fR5bSvZw+6uzKN1b7nckkZoVfLDURwKZZnYRsNs5p33wIpW0b5zJY1eexKyVW/n1OwsI7NUU8U9Nhyq4CpgBXAlcBUw3syu8DCYSiS7q0Ih7z2jN6/lrGD51hd9xJMbV9DTJRwicA78RwMxygPHAm14FE4lUg89qyzcbivnzB1/Tun46p7XN8TuSxKia7oOP21fuQZsPtqyZpZjZDDObZ2YLzez3h51SJILExRn/vKojbRtkcPdrs1leuMPvSBKjalrwH5vZJ2Z2o5ndCHwAfHiQZUqBM5xzJwEdgfPMrPvhRxWJHGnJCQy7Po/E+DhueSWf7bvK/I4kMaimB1kfAoYCHYK3oc65nx9kGeec27fpkhi86aiTxIymdVN5vn8XVm8t4Z5Rc9hbruGbJLRqfMEP59xbzrkHgrexNVnGzOLNbC6wERjnnJtexTyDzCzfzPILC3UVe4kuXVvW5Y992zNpSSF//Wix33EkxhxsP3qxmRVVcSs2s6KDfXHnXLlzriOB8+a7mln7KuYZ6pzLc87l5eToYJREn2u6NuPGU1vw4pRveUMXC5EQOuBZNM65ozIcgXNum5l9AZwHLDgaX1MkkvzqwuMp2LiDR8YuIDcnjS7N6/odSWKAZ9dkNbMcM8sK3q8FnA3of1SJSQnxcTzTrxONslK4bcQs1m7b5XckiQFeXnS7IfCFmc0HZhLYB/++h+sTCWtZqUm8eEMepWUV3PpKPiV79vodSaKcZwXvnJvvnOvknOvgnGvvnPuDV+sSiRSt62fw1LWdWPRdEQ+9MV/DGYinvNyCF5EqnH5cfR4+/zg++Go9T31W4HcciWI1HapARI6iW3vlsvi7Yh4fv4S2DdI5/8SGfkeSKKQteBEfmBn/d9mJdApeKOTrdQc961jkkKngRXySkhjPC/27kFkrkdtfncWOUh10laNLBS/io/q1U3jq2k6s2VrCH9/72u84EmVU8CI+69qyLnf0acWY/NV8vOA7v+NIFFHBi4SB+85sS/vGtXn47flsLNrtdxyJEip4kTCQlBDHE1d3YldZOQ+9qfPj5ehQwYuEidb103nkguOZuKSQEdNW+h1HooAKXiSM9O/enD7H5vDnDxZRsLHY7zgS4VTwImHEzPj7FR1IS05g8Ji57Nmri4TI4VPBi4SZ+hkp/OXyE1mwtognxi/xO45EMBW8SBg694RjuObkpjw3cRkzvt3idxyJUCp4kTD164va0axuKvePmUvRbl20Ww6dCl4kTKUlJ/D41R35rmg3v3t3od9xJAKp4EXCWOdmdbj79Na8PXst789f53cciTAqeJEwd/cZrenYNItHxi5g/XZd6k9qTgUvEuYS4+N4/OqOlJVX8NM35lFRoXe5Ss2o4EUiQMvsNH5zUTumFmzmX1+u8DuORAgVvEiEuPrkppx1fAP+9vFiFn+nC4TIwangRSKEmfG3n5xI7ZREBo+ey+6ycr8jSZhTwYtEkHrpyTx6RQcWf1fMPz79xu84EuZU8CIR5vTj6jOge3NenPItXxZs8juOhDHPCt7MmprZF2b2tZktNLP7vFqXSKz55QXH0zI7jQffmMf2Er3LVarm5Rb8XuBB51w7oDtwl5m183B9IjGjVlI8T1zdkcLiUh555ytdIESq5FnBO+fWO+dmB+8XA4uAxl6tTyTWdGiSxf1nt+X9+ev5z1y9y1V+LCT74M2sBdAJmB6K9YnEittPa8XJLerwq3cWsGpzid9xJMx4XvBmlg68BQx2zv3o5F0zG2Rm+WaWX1hY6HUckagSH2c8fnVH4gzuGT2HsnJdIET+x9OCN7NEAuU+0jn3dlXzOOeGOufynHN5OTk5XsYRiUpN6qTyt590YN7qbTymUyelEi/PojHgJWCRc+6fXq1HROD8ExvSr1szXpi4nElL9J+wBHi5Bd8DGACcYWZzg7cLPFyfSEz7zUXtaNsgnQden0dhcanfcSQMeHkWzRTnnDnnOjjnOgZvH3q1PpFYl5IYzzP9OlO8u4wHXp+rUSdF72QViSZtG2Twm4vbMXnpJoZNXu53HPGZCl4kyvTr2ozz2x/Do598w9zV2/yOIz5SwYtEGTPjr5d3oEHtFO4dNYdiXbA7ZqngRaJQZmoiT13bkbXbdvHI2AUayiBGqeBFolSX5nW5/6w2vDtvHW/MWuN3HPGBCl4kit3RpzWn5Nbjt/9ZSMHGHX7HkRBTwYtEsfg444lrOlIrKZ57Rs3RVaBijApeJMo1qJ3CY1d2YNH6Iv760WK/40gIqeBFYsAZxzXg5h4tefnLFYz7eoPfcSREVPAiMeLn5x/LCY1q89Cb81i/fZffcSQEVPAiMSI5IZ6nr+3Enr0VDB49l3INZRD1VPAiMSQ3J50/9m3P9G+38MznBX7HEY+p4EVizE+6NOGyTo158rMlzPh2i99xxEMqeJEY9MdL29O0biqDR89hW8kev+OIR1TwIjEoPTmBp6/tROGOUn7+1nwNZRClVPAiMapDkyx+du5xfLJwAyOmrfQ7jnhABS8Swwb2bMkZx9Xnd+8u5IP56/2OI0eZCl4khsXFGU9f24nOzepw3+g5ehNUlFHBi8S4tOQE/nXTyZzQOJO7Rs5mwjcb/Y4kR4kKXkTISEnk3zd1pU2DdG4bMYupBZv8jiRHgQpeRIDARUJGDOxGi3pp3PJKvs6RjwIqeBH5Xt20JF69pRsNs1K46V8zmL1qq9+R5Aio4EXkB3Iyknntlu5kZyRzw/AZfLVmu9+R5DCp4EXkR47JTOG1W7tTOyWRAcOns2h9kd+R5DB4VvBmNtzMNprZAq/WISLeaZxVi1G3diclIZ7+L05n6YZivyPJIfJyC/5l4DwPv76IeKxZvVReu7UbcXFGvxen8+2mnX5HkkPgWcE75yYBOgwvEuFyc9J57ZZulFc4+g2bxuotJX5HkhryfR+8mQ0ys3wzyy8sLPQ7johUoU2DDF4d2I2SPeVcO2waa7fpilCRwPeCd84Ndc7lOefycnJy/I4jItVo16g2IwZ2ZXtJGdcNm8aGot1+R5KD8L3gRSRydGiSxcs3d6WwuJR+w6axaUep35HkAFTwInJIujSvw/AbT2bttl30f3E6W3fqgiHhysvTJEcB/wWONbM1ZjbQq3WJSGh1y63Hi9efzPJNO+n/0nS27yrzO5JUwcuzaK51zjV0ziU655o4517yal0iEno922TzwoAuLNlQzOXPTmXCNxt1Zagwo100InLYTj+2PsNvPJm9FY4b/zWTAS/NYOE6DW0QLlTwInJEerXJYdz9p/Gbi9qxYN12Lnp6Cj99Yx7rt+tUSr9ZOP1LlZeX5/Lz8/2OISKHafuuMp79ooB/TV1BXBzc0jOX207LJSMl0e9oUcvMZjnn8qqapi14ETlqMmsl8vAFx/PZg6dx7gnH8MwXBfR5dAIjpq2krLzC73gxRwUvIkdd07qpPHlNJ969uwet6qfz63cWcO4Tkxj39QYdiA0hFbyIeKZDkyzGDOrOsOsDexBu/Xc+Vw+dxrzV23xOFhtU8CLiKTPj7HYN+GRwb/54aXuWbdxB3yFTuW/0HA1c5jEdZBWRkCreXcYLE5czbPJynIMbe7Tgzj6tyEpN8jtaRDrQQVYVvIj4Yv32XTz2yRLenrOGeDM6N69D7zbZ9GqTQ/vGmcTHmd8RI4IKXkTC1qL1Rfxn7jomLy1k4brApQHrpCbSo3U2vdvk0LNNNo2yavmcMnyp4EUkImzaUcrUgk1MWrKJyUsL2VgcGK2ydf10erUJFH633LqkJiX4nDR8qOBFJOI451iyYQeTlxYyaekmpi/fTOneCpLi48hrUYdebXLo1Sabdg1rExfDu3NU8CIS8XaXlZO/Yuv3hb9ofWB3Tr20JPJa1CE3J53c7LTvP9ZJi42Dtip4EYk6G4t3f787Z96abazaXMLeiv/1WZ3URHJz0mmZnUZuThq52enk5qTRvF4qyQnxPiY/ulTwIhL19pZXsHrrLpYX7uDbTTtZVrjz+/v79uUDxBk0qZP6v+LPSadZ3VRy0pPJyUimblpSRJ3Bc6CC15EKEYkKCfFxtMxOo2V22o+mFe8u49tNO39U/DNXbKFkT/kP5o0zqJsWKPucjGRy0pPJzkj6/g9ATkYy9TOSyU5PJrNWImbh+8dABS8iUS8jJZEOTbLo0CTrB48759hQVMrqrSVsKi5l045SCotLKfz+4x6WbdxBYXEpe6oYLC0pPo7s9CTqpidROyWR2imJZKQkULtW4H7tWglkpCRSu9Jj+6ZnJCd4fnBYBS8iMcvMOCYzhWMyUw44n3OOol17KxV/KZsq/SHYsnPP9/8lFO0uo3j3XnaU7j3IuiE9OYHaKYk0ykrhjdtPPZrfGqCCFxE5KDMjMzWRzNREWtdPr9Eye8sr2FG6l6JdeynaXRa47bu/q4yi3XspDj6WGO/NlqPWbj8AAAd3SURBVLwKXkTEAwnxcWSlJvk6xo5GkxQRiVIqeBGRKKWCFxGJUp4WvJmdZ2bfmFmBmf3Cy3WJiMgPeVbwZhYPDAHOB9oB15pZO6/WJyIiP+TlFnxXoMA5t9w5twcYDfT1cH0iIlKJlwXfGFhd6fM1wcd+wMwGmVm+meUXFhZ6GEdEJLb4fpDVOTfUOZfnnMvLycnxO46ISNTw8o1Oa4GmlT5vEnysWrNmzdpkZisPc33ZwKbDXDYUlO/IKN+RUb4jE875mlc3wbPhgs0sAVgCnEmg2GcC/ZxzCz1aX351Q2aGA+U7Msp3ZJTvyIR7vup4tgXvnNtrZncDnwDxwHCvyl1ERH7M07FonHMfAh96uQ4REama7wdZj6Khfgc4COU7Msp3ZJTvyIR7viqF1SX7RETk6ImmLXgREalEBS8iEqUiruAPNoCZmSWb2Zjg9Olm1iKE2Zqa2Rdm9rWZLTSz+6qYp4+ZbTezucHbb0KVL7j+FWb2VXDd+VVMNzN7Kvj8zTezziHMdmyl52WumRWZ2eD95gnp82dmw81so5ktqPRYXTMbZ2ZLgx/rVLPsDcF5lprZDSHM96iZLQ7+/MaaWVY1yx7wteBhvt+Z2dpKP8MLqlnW88EKq8k3plK2FWY2t5plPX/+jphzLmJuBE63XAbkAknAPKDdfvPcCTwfvH8NMCaE+RoCnYP3Mwi8D2D/fH2A9318DlcA2QeYfgHwEWBAd2C6jz/r74Dmfj5/QG+gM7Cg0mN/B34RvP8L4G9VLFcXWB78WCd4v06I8p0DJATv/62qfDV5LXiY73fAT2vw8z/g77pX+fab/g/gN349f0d6i7Qt+JoMYNYXeCV4/03gTDPz9tLlQc659c652cH7xcAiqhh/J8z1Bf7tAqYBWWbW0IccZwLLnHOH+87mo8I5NwnYst/DlV9jrwCXVrHoucA459wW59xWYBxwXijyOec+dc7tu+LzNALvIvdFNc9fTYRksMID5Qv2xlXAqKO93lCJtIKvyQBm388TfJFvB+qFJF0lwV1DnYDpVUw+xczmmdlHZnZCSIOBAz41s1lmNqiK6TUaJC4ErqH6Xyw/nz+ABs659cH73wENqpgnXJ7Hmwn8R1aVg70WvHR3cBfS8Gp2cYXD89cL2OCcW1rNdD+fvxqJtIKPCGaWDrwFDHbOFe03eTaB3Q4nAU8D74Q4Xk/nXGcC4/TfZWa9Q7z+gzKzJOAS4I0qJvv9/P2AC/yvHpbnGpvZI8BeYGQ1s/j1WngOaAV0BNYT2A0Sjq7lwFvvYf+7FGkFX5MBzL6fJzgeTiawOSTpAutMJFDuI51zb+8/3TlX5JzbEbz/IZBoZtmhyuecWxv8uBEYS+Bf4coOeZA4D5wPzHbObdh/gt/PX9CGfbutgh83VjGPr8+jmd0IXARcF/wj9CM1eC14wjm3wTlX7pyrAIZVs16/n78E4HJgTHXz+PX8HYpIK/iZQBszaxncyrsGeHe/ed4F9p2xcAXweXUv8KMtuM/uJWCRc+6f1cxzzL5jAmbWlcDPICR/gMwszcwy9t0ncDBuwX6zvQtcHzybpjuwvdLuiFCpdsvJz+evksqvsRuA/1QxzyfAOWZWJ7gL4pzgY54zs/OAnwGXOOdKqpmnJq8Fr/JVPqZzWTXrrcnvupfOAhY759ZUNdHP5++Q+H2U91BvBM7yWELgCPsjwcf+QODFDJBC4F/7AmAGkBvCbD0J/Ls+H5gbvF0A3A7cHpznbmAhgbMCpgGnhjBfbnC984IZ9j1/lfMZgUstLgO+AvJC/PNNI1DYmZUe8+35I/CHZj1QRmA/8EACx3Q+A5YC44G6wXnzgBcrLXtz8HVYANwUwnwFBPZf73sN7jurrBHw4YFeCyHKNyL42ppPoLQb7p8v+PmPftdDkS/4+Mv7XnOV5g3583ekNw1VICISpSJtF42IiNSQCl5EJEqp4EVEopQKXkQkSqngRUSilApe5CgIjnL5vt85RCpTwYuIRCkVvMQUM+tvZjOCY3i/YGbxZrbDzB63wBj+n5lZTnDejmY2rdK46nWCj7c2s/HBAc9mm1mr4JdPN7M3g2OxjwzVKKYi1VHBS8wws+OBq4EezrmOQDlwHYF3z+Y7504AJgK/DS7yb+DnzrkOBN55ue/xkcAQFxjw7FQC74SEwOihg4F2BN7p2MPzb0rkABL8DiASQmcCXYCZwY3rWgQGCqvgf4NKvQq8bWaZQJZzbmLw8VeAN4LjjzR2zo0FcM7tBgh+vRkuOHZJ8CpALYAp3n9bIlVTwUssMeAV59zDP3jQ7Nf7zXe443eUVrpfjn6/xGfaRSOx5DPgCjOrD99fW7U5gd+DK4Lz9AOmOOe2A1vNrFfw8QHARBe4UtcaM7s0+DWSzSw1pN+FSA1pC0NihnPuazP7FYGr8MQRGEHwLmAn0DU4bSOB/fQQGAr4+WCBLwduCj4+AHjBzP4Q/BpXhvDbEKkxjSYpMc/Mdjjn0v3OIXK0aReNiEiU0ha8iEiU0ha8iEiUUsGLiEQpFbyISJRSwYuIRCkVvIhIlPp/fxQdVaKIrzAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "fc0b01df-02ac-42a6-ae57-212beef3bb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "存在且應該維下去的友。豬和人類之間沒有、\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "在且應該維下去的友。豬和人類之間沒有、也\n"
          ]
        }
      ],
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "outputs": [],
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7ELuAjW3rKW",
        "outputId": "c6e28da2-5b43-4ad9-d99c-19bcbf52a845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "拿破崙的見解是，動物們現在要做的是法取得槍望，而且動物們如此自己的心思還不如。他們說，這些歌實不會到現在，但我們想說，或許不多他們這些豬律背記。他們很清楚這一切為的不是會會，但他們的事實也有表樣。\n",
            "「同志們，你們要不知道，」雪球說：「現在是六點半，高唱之著，他們都沒自己之後，或許是否有動物英一等勳章嗎？」\n",
            "「同志，前進！」或者「同志們，我們要把你們的時候是我們想想，對吧？」\n",
            "這讓大家停了，這些豬議在子上看起來，我們要收割乾草，但在這次人不了。\n",
            "「同志們，你們已經聽說，」他說道：「現在是六點半，高下之蹄、的人類先行，而且動物們無理意見，他們想到自己的食物了。他們了一些動物，連時裡也加真的，但是少少清楚自己有責任何經，那麼，他們的理任。各是我們不了，我們的決體絕不是做，但我們只要言到主利，但有人類有那麼都是了。他們，不能發生什麼事情？」\n",
            "「不是」，這些動物皆被當場，但他們樂到自己記錯了。\n",
            "天裡，尖叫者把兩條狗當外的小狗，他們從為從望，他們的話可能把新留的蛋，雪球常靠出色演說取得多數動物認同。大家注，如果這鼠是我們的話，更加了一些重要的事情。許多，這個意見，或許多少好好或改變，因為他們的話。他現在"
          ]
        }
      ],
      "source": [
        "init_seq = \"拿破崙\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "outputs": [],
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TextGeneration-107401511.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
